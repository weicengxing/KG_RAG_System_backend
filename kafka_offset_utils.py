"""
Kafka Offset å·¥å…·
ç”¨äºæŸ¥è¯¢æŒ‡å®šæ—¶é—´èŒƒå›´çš„ Kafka offsetï¼Œä¼˜åŒ– Spark æ‰¹å¤„ç†è¯»å–æ€§èƒ½
"""

import logging
import json
from datetime import datetime
from typing import Dict, Optional, Tuple
from confluent_kafka import Consumer, KafkaError, TopicPartition

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# Kafka é…ç½®
KAFKA_BOOTSTRAP_SERVERS = 'localhost:9092'
MUSIC_PLAY_EVENTS_TOPIC = 'music-play-events'


def get_kafka_consumer() -> Consumer:
    """åˆ›å»º Kafka æ¶ˆè´¹è€…ï¼ˆä»…ç”¨äºæŸ¥è¯¢ offsetï¼‰

    Returns:
        Consumer: Kafka æ¶ˆè´¹è€…å®ä¾‹
    """
    conf = {
        'bootstrap.servers': KAFKA_BOOTSTRAP_SERVERS,
        'group.id': 'spark-offset-query',  # ä¸´æ—¶ group idï¼Œä¸ä¼šå®é™…æ¶ˆè´¹
        'enable.auto.commit': False,  # ä¸è‡ªåŠ¨æäº¤
        'auto.offset.reset': 'earliest',  # ä»æœ€æ—©å¼€å§‹
        'session.timeout.ms': 10000,  # 10ç§’è¶…æ—¶
    }
    
    consumer = Consumer(conf)
    return consumer


def get_partitions_for_topic(topic: str, consumer: Consumer) -> list[int]:
    """è·å– topic çš„æ‰€æœ‰åˆ†åŒº

    Args:
        topic: topic åç§°
        consumer: Kafka æ¶ˆè´¹è€…

    Returns:
        list[int]: åˆ†åŒºåˆ—è¡¨
    """
    cluster_metadata = consumer.list_topics(topic)
    topic_metadata = cluster_metadata.topics.get(topic)
    
    if not topic_metadata:
        raise ValueError(f"Topic {topic} ä¸å­˜åœ¨")
    
    partitions = list(topic_metadata.partitions.keys())
    logger.info(f"âœ… Topic {topic} æœ‰ {len(partitions)} ä¸ªåˆ†åŒº: {partitions}")
    
    return partitions


def get_offsets_by_timestamp(
    consumer: Consumer,
    topic: str,
    start_timestamp_ms: int,
    end_timestamp_ms: int
) -> Dict[str, Dict]:
    """æŸ¥è¯¢æŒ‡å®šæ—¶é—´èŒƒå›´çš„ offset

    Args:
        consumer: Kafka æ¶ˆè´¹è€…
        topic: topic åç§°
        start_timestamp_ms: å¼€å§‹æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
        end_timestamp_ms: ç»“æŸæ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰

    Returns:
        Dict[str, Dict]: Spark å¯ç”¨çš„ offset æ ¼å¼
            {
                "startingOffsets": {
                    "topic": {"partition": offset, ...}
                },
                "endingOffsets": {
                    "topic": {"partition": offset, ...}
                }
            }
    """
    logger.info(f"ğŸ” æŸ¥è¯¢ offset èŒƒå›´: topic={topic}")
    logger.info(f"   - å¼€å§‹æ—¶é—´: {datetime.fromtimestamp(start_timestamp_ms / 1000)}")
    logger.info(f"   - ç»“æŸæ—¶é—´: {datetime.fromtimestamp(end_timestamp_ms / 1000)}")
    
    # è·å–æ‰€æœ‰åˆ†åŒº
    partitions = get_partitions_for_topic(topic, consumer)
    
    # æŸ¥è¯¢èµ·å§‹ offset
    start_offsets = {}
    for partition in partitions:
        tp = TopicPartition(topic, partition)
        
        # æŸ¥æ‰¾å¤§äºç­‰äº start_timestamp çš„ç¬¬ä¸€ä¸ª offset
        offsets = consumer.offsets_for_times({tp: start_timestamp_ms})
        
        if offsets and offsets[tp]:
            start_offset = offsets[tp].offset
            logger.info(f"   - åˆ†åŒº {partition}: èµ·å§‹ offset={start_offset}")
        else:
            # æ²¡æœ‰æ‰¾åˆ°è¯¥æ—¶é—´ç‚¹ä¹‹åçš„ offsetï¼Œè¯´æ˜è¯¥åˆ†åŒºæ²¡æœ‰æ•°æ®
            # ä½¿ç”¨ earliest offset
            try:
                earliest = consumer.get_watermark_offsets(tp)[0]
                start_offset = earliest
                logger.warning(f"   - åˆ†åŒº {partition}: æœªæ‰¾åˆ°æ—¶é—´ç‚¹å¯¹åº”çš„ offsetï¼Œä½¿ç”¨ earliest={start_offset}")
            except KafkaError as e:
                logger.error(f"   - åˆ†åŒº {partition}: è·å– earliest offset å¤±è´¥: {e}")
                start_offset = 0
        
        start_offsets[str(partition)] = start_offset
    
    # æŸ¥è¯¢ç»“æŸ offset
    end_offsets = {}
    for partition in partitions:
        tp = TopicPartition(topic, partition)
        
        # æŸ¥æ‰¾å¤§äºç­‰äº end_timestamp çš„ç¬¬ä¸€ä¸ª offset
        offsets = consumer.offsets_for_times({tp: end_timestamp_ms})
        
        if offsets and offsets[tp]:
            end_offset = offsets[tp].offset
            logger.info(f"   - åˆ†åŒº {partition}: ç»“æŸ offset={end_offset}")
        else:
            # æ²¡æœ‰æ‰¾åˆ°è¯¥æ—¶é—´ç‚¹ä¹‹åçš„ offsetï¼Œè¯´æ˜è¯¥åˆ†åŒºæ•°æ®æ—©äºè¯¥æ—¶é—´ç‚¹
            # ä½¿ç”¨ latest offsetï¼ˆæœ€æ–°ï¼‰
            try:
                latest = consumer.get_watermark_offsets(tp)[1]
                end_offset = latest
                logger.warning(f"   - åˆ†åŒº {partition}: æœªæ‰¾åˆ°æ—¶é—´ç‚¹å¯¹åº”çš„ offsetï¼Œä½¿ç”¨ latest={end_offset}")
            except KafkaError as e:
                logger.error(f"   - åˆ†åŒº {partition}: è·å– latest offset å¤±è´¥: {e}")
                end_offset = -1  # -1 è¡¨ç¤º latest
        
        end_offsets[str(partition)] = end_offset
    
    # æ„å»º Spark offset æ ¼å¼
    spark_start_offsets = {topic: start_offsets}
    spark_end_offsets = {topic: end_offsets}
    
    logger.info(f"âœ… Offset æŸ¥è¯¢å®Œæˆ")
    logger.info(f"   - startingOffsets: {json.dumps(spark_start_offsets)}")
    logger.info(f"   - endingOffsets: {json.dumps(spark_end_offsets)}")
    
    return {
        'startingOffsets': json.dumps(spark_start_offsets),
        'endingOffsets': json.dumps(spark_end_offsets)
    }


def get_offset_range_summary(
    consumer: Consumer,
    topic: str,
    start_timestamp_ms: int,
    end_timestamp_ms: int
) -> Tuple[int, int]:
    """ä¼°ç®—æ—¶é—´èŒƒå›´å†…çš„æ¶ˆæ¯æ•°é‡

    Args:
        consumer: Kafka æ¶ˆè´¹è€…
        topic: topic åç§°
        start_timestamp_ms: å¼€å§‹æ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰
        end_timestamp_ms: ç»“æŸæ—¶é—´æˆ³ï¼ˆæ¯«ç§’ï¼‰

    Returns:
        Tuple[int, int]: (æ¶ˆæ¯æ•°é‡, åˆ†åŒºæ•°é‡)
    """
    try:
        partitions = get_partitions_for_topic(topic, consumer)
        offset_info = get_offsets_by_timestamp(consumer, topic, start_timestamp_ms, end_timestamp_ms)
        
        start_offsets = json.loads(offset_info['startingOffsets'])[topic]
        end_offsets = json.loads(offset_info['endingOffsets'])[topic]
        
        total_messages = 0
        for partition in partitions:
            start = start_offsets[str(partition)]
            end = end_offsets[str(partition)]
            
            if end == -1:  # latest offsetï¼Œæ— æ³•è®¡ç®—ç¡®åˆ‡æ•°é‡
                total_messages = -1  # -1 è¡¨ç¤ºæ— æ³•ä¼°ç®—
                break
            
            messages = end - start
            total_messages += messages
        
        if total_messages == -1:
            logger.warning(f"âš ï¸ æ— æ³•å‡†ç¡®ä¼°ç®—æ¶ˆæ¯æ•°é‡ï¼ˆæŸä¸ªåˆ†åŒºä½¿ç”¨äº† latest offsetï¼‰")
        else:
            logger.info(f"âœ… ä¼°ç®—æ¶ˆæ¯æ•°é‡: {total_messages} æ¡")
        
        return total_messages, len(partitions)
        
    except Exception as e:
        logger.error(f"âŒ ä¼°ç®—æ¶ˆæ¯æ•°é‡å¤±è´¥: {e}")
        return -1, 0


def main():
    """æµ‹è¯•å‡½æ•°"""
    import sys
    from datetime import timedelta
    
    if len(sys.argv) < 2:
        print("Usage: python kafka_offset_utils.py <hours_ago>")
        print("Example: python kafka_offset_utils.py 24")
        sys.exit(1)
    
    hours_ago = int(sys.argv[1])
    
    # è®¡ç®—æ—¶é—´èŒƒå›´
    end_time = datetime.now()
    start_time = end_time - timedelta(hours=hours_ago)
    
    start_timestamp_ms = int(start_time.timestamp() * 1000)
    end_timestamp_ms = int(end_time.timestamp() * 1000)
    
    print(f"\nğŸš€ å¼€å§‹æŸ¥è¯¢ offset èŒƒå›´...")
    print(f"   - æ—¶é—´èŒƒå›´: {start_time} åˆ° {end_time} ({hours_ago} å°æ—¶)")
    
    try:
        consumer = get_kafka_consumer()
        
        # æŸ¥è¯¢ offset
        offset_info = get_offsets_by_timestamp(
            consumer,
            MUSIC_PLAY_EVENTS_TOPIC,
            start_timestamp_ms,
            end_timestamp_ms
        )
        
        # ä¼°ç®—æ¶ˆæ¯æ•°é‡
        total_messages, partition_count = get_offset_range_summary(
            consumer,
            MUSIC_PLAY_EVENTS_TOPIC,
            start_timestamp_ms,
            end_timestamp_ms
        )
        
        print(f"\nâœ… æŸ¥è¯¢å®Œæˆ:")
        print(f"   - åˆ†åŒºæ•°: {partition_count}")
        print(f"   - ä¼°ç®—æ¶ˆæ¯æ•°: {total_messages if total_messages > 0 else 'æ— æ³•ä¼°ç®—'}")
        print(f"   - startingOffsets: {offset_info['startingOffsets']}")
        print(f"   - endingOffsets: {offset_info['endingOffsets']}")
        
        consumer.close()
        
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
