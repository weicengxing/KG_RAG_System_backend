"""
çŸ¥è¯†å›¾è°±RAGç³»ç»ŸAPIè·¯ç”±
æ”¯æŒ Kafka å¼‚æ­¥å¤„ç† + SSE å®æ—¶è¿›åº¦æ¨é€
"""

from fastapi import APIRouter, UploadFile, File, HTTPException, Request, Depends, Query
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
import os
import uuid
import time
import asyncio
import hashlib
import json
from datetime import datetime
from kg_service import kg_service
from database_asy_mon_re import db_manager
from task_manager import task_manager
from confluent_kafka import Producer as KafkaProducer
from auth_deps import get_current_user, get_current_user_from_query

router = APIRouter(prefix="/api/kg", tags=["Knowledge Graph"])

# å¯¼å…¥å¸ƒéš†è¿‡æ»¤å™¨å·¥å…·å‡½æ•°
try:
    from bloom_utils import is_document_uploaded, is_document_uploaded_with_warmup, mark_document_uploaded
except ImportError:
    # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨ç©ºå‡½æ•°
    def is_document_uploaded(doc_id): return False
    def is_document_uploaded_with_warmup(doc_id, fallback_to_db=False): return (False, False)
    def mark_document_uploaded(doc_id): pass

# æ–‡æ¡£ä¸Šä¼ ç›®å½•
UPLOAD_DIR = os.path.join(os.path.dirname(__file__), "uploads")
os.makedirs(UPLOAD_DIR, exist_ok=True)


# ==================== è¾…åŠ©å‡½æ•° ====================

async def save_document_metadata_async(
    doc_id: str,
    file_hash: str,
    filename: str,
    file_extension: str,
    file_size: int,
    file_path: str,
    text_length: int
):
    """
    å¼‚æ­¥ä¿å­˜æ–‡æ¡£å…ƒæ•°æ®åˆ° MongoDB
    
    Args:
        doc_id: æ–‡æ¡£ID (UUID)
        file_hash: æ–‡ä»¶MD5 hash
        filename: åŸå§‹æ–‡ä»¶å
        file_extension: æ–‡ä»¶æ‰©å±•å
        file_size: æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        file_path: æ–‡ä»¶ä¿å­˜è·¯å¾„
        text_length: æ–‡æœ¬é•¿åº¦
    """
    try:
        document_data = {
            "doc_id": doc_id,
            "file_hash": file_hash,
            "filename": filename,
            "file_extension": file_extension,
            "file_size": file_size,
            "file_path": file_path,
            "text_length": text_length,
            "upload_time": datetime.utcnow(),
            "status": "uploaded"
        }
        
        # å¼‚æ­¥æ’å…¥åˆ° MongoDB
        await db_manager.db.documents.insert_one(document_data)
        print(f"âœ… æ–‡æ¡£å…ƒæ•°æ®å·²ä¿å­˜åˆ°MongoDB: {doc_id} ({filename})")
    except Exception as e:
        # å¦‚æœä¿å­˜å¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ä¸å½±å“ä¸»æµç¨‹
        print(f"âŒ ä¿å­˜æ–‡æ¡£å…ƒæ•°æ®å¤±è´¥: {e}")
        import traceback
        import logging
        logger = logging.getLogger(__name__)
        logger.error(f"ä¿å­˜æ–‡æ¡£å…ƒæ•°æ®åˆ°MongoDBå¤±è´¥: doc_id={doc_id}, error={str(e)}")
        logger.exception(traceback.format_exc())


# ==================== è¯·æ±‚/å“åº”æ¨¡å‹ ====================

class QuestionRequest(BaseModel):
    """é—®ç­”è¯·æ±‚"""
    question: str
    stream: bool = False
    conversation_id: Optional[str] = None  # å¯¹è¯IDï¼Œç”¨äºä»Redisè·å–å¯¹è¯å†å²
    model_name: Optional[str] = None  # AIé—®ç­”æ¨¡å‹åç§°


class GraphQueryRequest(BaseModel):
    """å›¾è°±æŸ¥è¯¢è¯·æ±‚"""
    doc_id: Optional[str] = None
    limit: int = 100


# ==================== æ–‡æ¡£ä¸Šä¼ ä¸å¤„ç† ====================

@router.post("/upload-document")
async def upload_document(file: UploadFile = File(...)):
    """
    ä¸Šä¼ æ–‡æ¡£ï¼ˆPDF/TXT/DOCX/PPTXï¼‰
    è¿”å›ï¼šæ–‡æ¡£IDå’Œæ–‡æœ¬å†…å®¹
    ä½¿ç”¨å¸ƒéš†è¿‡æ»¤å™¨é˜²æ­¢é‡å¤ä¸Šä¼ 
    """
    # éªŒè¯æ–‡ä»¶ç±»å‹
    allowed_extensions = {'.pdf', '.txt', '.docx', '.pptx'}
    file_ext = os.path.splitext(file.filename)[1].lower()
    if file_ext not in allowed_extensions:
        raise HTTPException(status_code=400, detail="åªæ”¯æŒ PDFã€TXTã€DOCXã€PPTX æ–‡ä»¶")

    # è¯»å–æ–‡ä»¶å†…å®¹å¹¶è®¡ç®— MD5 hash
    try:
        content = await file.read()
        file_hash = hashlib.md5(content).hexdigest()
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")

    # ä½¿ç”¨å¸ƒéš†è¿‡æ»¤å™¨å¿«é€Ÿæ£€æŸ¥ï¼ˆæ”¯æŒWarmupé™çº§ï¼‰
    doc_exists, used_db_fallback = is_document_uploaded_with_warmup(
        file_hash, 
        fallback_to_db=True  # Warmupæœªå®Œæˆæ—¶é™çº§åˆ°MongoDBæŸ¥è¯¢
    )
    
    if doc_exists:
        # ä» MongoDB æŸ¥è¯¢å·²å­˜åœ¨æ–‡æ¡£çš„è¯¦ç»†ä¿¡æ¯
        existing_doc = await db_manager.db.documents.find_one({"file_hash": file_hash})
        
        # æ ¼å¼åŒ–è¿”å›æ•°æ®
        existing_doc_data = None
        if existing_doc:
            # è½¬æ¢ ObjectId ä¸ºå­—ç¬¦ä¸²ï¼Œå¹¶æ ¼å¼åŒ–æ—¶é—´
            existing_doc_data = {
                "doc_id": existing_doc.get("doc_id"),
                "filename": existing_doc.get("filename"),
                "file_hash": existing_doc.get("file_hash"),
                "file_extension": existing_doc.get("file_extension"),
                "file_size": existing_doc.get("file_size"),
                "text_length": existing_doc.get("text_length"),
                "upload_time": existing_doc.get("upload_time").isoformat() if existing_doc.get("upload_time") else None,
                "status": existing_doc.get("status", "unknown")
            }
        
        return {
            "error": "æ–‡æ¡£å·²å­˜åœ¨",
            "duplicate": True,
            "file_hash": file_hash,
            "existing_doc": existing_doc_data,
            "message": "è¯¥æ–‡æ¡£å·²ä¸Šä¼ è¿‡ï¼Œæ˜¯å¦æŸ¥çœ‹å·²æœ‰çŸ¥è¯†å›¾è°±ï¼Ÿ"
        }

    # ç”Ÿæˆæ–‡æ¡£ID
    doc_id = str(uuid.uuid4())

    # ä¿å­˜æ–‡ä»¶
    file_path = os.path.join(UPLOAD_DIR, f"{doc_id}{file_ext}")
    try:
        with open(file_path, "wb") as f:
            f.write(content)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)}")

    # æ ‡è®°æ–‡æ¡£å·²ä¸Šä¼ ï¼ˆæ·»åŠ åˆ°å¸ƒéš†è¿‡æ»¤å™¨ï¼Œä½¿ç”¨ force_save=True ç«‹å³ä¿å­˜ï¼‰
    mark_document_uploaded(file_hash, force_save=True)

    # è§£ææ–‡æ¡£
    try:
        text = kg_service.parse_document(file_path)
        text_length = len(text)

        # å¼‚æ­¥ä¿å­˜æ–‡æ¡£å…ƒæ•°æ®åˆ°MongoDBï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
        asyncio.create_task(
            save_document_metadata_async(
                doc_id=doc_id,
                file_hash=file_hash,
                filename=file.filename,
                file_extension=file_ext,
                file_size=len(content),
                file_path=file_path,
                text_length=text_length
            )
        )

        return {
            "doc_id": doc_id,
            "filename": file.filename,
            "text_preview": text[:500],  # é¢„è§ˆå‰500å­—ç¬¦
            "text_length": text_length,
            "file_hash": file_hash,
            "message": "æ–‡æ¡£ä¸Šä¼ æˆåŠŸ"
        }
    except Exception as e:
        # æ¸…ç†æ–‡ä»¶
        if os.path.exists(file_path):
            os.remove(file_path)
        raise HTTPException(status_code=500, detail=str(e))


# ==================== æ–‡æœ¬åˆ†å— ====================

@router.post("/split-text")
async def split_text(
    request: Request,
    current_user: str = Depends(get_current_user)
):
    """
    æ–‡æœ¬åˆ†å—
    è¿”å›ï¼šåˆ†å—åˆ—è¡¨
    
    Args:
        request: FastAPI è¯·æ±‚å¯¹è±¡
        current_user: å½“å‰ç”¨æˆ·ï¼ˆä» JWT token è·å–ï¼‰
    """
    print(f"[split-text] ğŸ”µ æ”¶åˆ°è¯·æ±‚ | å½“å‰ç”¨æˆ·: {current_user}")
    
    try:
        # æ‰“å°è¯·æ±‚å¤´çš„ Content-Type
        content_type = request.headers.get("content-type", "")
        print(f"[split-text] ğŸ“‹ Content-Type: {content_type}")
        
        # æ‰“å°åŸå§‹è¯·æ±‚ä½“ï¼ˆä»…æ‰“å°å‰500å­—ç¬¦ä»¥é¿å…æ—¥å¿—è¿‡é•¿ï¼‰
        body_bytes = await request.body()
        print(f"[split-text] ğŸ“¦ è¯·æ±‚ä½“åŸå§‹å­—èŠ‚ (å‰500å­—ç¬¦): {body_bytes[:500]}")
        
        # å°è¯•è§£æ JSON
        try:
            body = await request.json()
            print(f"[split-text] âœ… JSON è§£ææˆåŠŸ: {body}")
        except Exception as json_error:
            print(f"[split-text] âŒ JSON è§£æå¤±è´¥: {json_error}")
            print(f"[split-text] âŒ åŸå§‹è¯·æ±‚ä½“å†…å®¹: {body_bytes.decode('utf-8', errors='replace')}")
            raise HTTPException(
                status_code=400, 
                detail=f"JSON è§£æå¤±è´¥: {str(json_error)}"
            )
        
        doc_id = body.get("doc_id")
        print(f"[split-text] ğŸ“„ è·å–åˆ°çš„ doc_id: {doc_id}")
        
        if not doc_id:
            print(f"[split-text] âš ï¸ doc_id ä¸ºç©º")
            raise HTTPException(status_code=400, detail="doc_id ä¸èƒ½ä¸ºç©º")
            
    except HTTPException:
        # é‡æ–°æŠ›å‡º HTTPException
        raise
    except Exception as e:
        print(f"[split-text] âŒ æœªçŸ¥é”™è¯¯: {e}")
        import traceback
        print(f"[split-text] âŒ é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        raise HTTPException(status_code=400, detail=f"è¯·æ±‚å¤„ç†å¤±è´¥: {str(e)}")
    
    # æŸ¥æ‰¾æ–‡æ¡£æ–‡ä»¶
    file_path = None
    for ext in ['.pdf', '.txt', '.docx', '.pptx']:
        path = os.path.join(UPLOAD_DIR, f"{doc_id}{ext}")
        if os.path.exists(path):
            file_path = path
            break

    if not file_path:
        raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")

    try:
        # è§£ææ–‡æ¡£
        text = kg_service.parse_document(file_path)

        # åˆ†å—
        chunks = kg_service.split_text(text)

        return {
            "doc_id": doc_id,
            "chunks": chunks,
            "total_chunks": len(chunks),
            "message": "æ–‡æœ¬åˆ†å—å®Œæˆ"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ==================== å®ä½“å…³ç³»æŠ½å– ====================

@router.post("/extract-entities")
async def extract_entities(
    request: Request,
    current_user: str = Depends(get_current_user)
):
    """
    å®ä½“å…³ç³»æŠ½å–ï¼ˆä½¿ç”¨LLMï¼‰
    è¿”å›ï¼šä¸‰å…ƒç»„åˆ—è¡¨ï¼ˆæµå¼è¿”å›æ¯ä¸ªå—çš„å¤„ç†ç»“æœï¼‰
    
    Args:
        request: FastAPI è¯·æ±‚å¯¹è±¡
        current_user: å½“å‰ç”¨æˆ·ï¼ˆä» JWT token è·å–ï¼‰
    """
    try:
        body = await request.json()
        doc_id = body.get("doc_id")
        
        if not doc_id:
            raise HTTPException(status_code=400, detail="doc_id ä¸èƒ½ä¸ºç©º")
    except Exception as e:
        raise HTTPException(status_code=400, detail="è¯·æ±‚ä½“æ ¼å¼é”™è¯¯")
    
    # æŸ¥æ‰¾æ–‡æ¡£æ–‡ä»¶
    file_path = None
    for ext in ['.pdf', '.txt', '.docx', '.pptx']:
        path = os.path.join(UPLOAD_DIR, f"{doc_id}{ext}")
        if os.path.exists(path):
            file_path = path
            break

    if not file_path:
        raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")

    try:
        # è§£æå’Œåˆ†å—
        text = kg_service.parse_document(file_path)
        chunks = kg_service.split_text(text)

        # å¹¶å‘æŠ½å–å®ä½“å…³ç³»
        triplets = await kg_service.extract_batch_async(chunks)

        return {
            "doc_id": doc_id,
            "triplets": triplets,
            "total_triplets": len(triplets),
            "message": "å®ä½“å…³ç³»æŠ½å–å®Œæˆ"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ==================== å›¾è°±æ„å»º ====================

@router.post("/build-graph")
async def build_graph(
    request: Request,
    current_user: str = Depends(get_current_user)
):
    """
    æ„å»ºçŸ¥è¯†å›¾è°±ï¼ˆå®Œæ•´æµç¨‹ï¼‰
    1. è§£ææ–‡æ¡£
    2. æ–‡æœ¬åˆ†å—
    3. å®ä½“å…³ç³»æŠ½å–
    4. ä¿å­˜åˆ°Neo4j
    5. ä¿å­˜åˆ°ChromaDBï¼ˆå‘é‡å­˜å‚¨ï¼‰
    
    Args:
        request: FastAPI è¯·æ±‚å¯¹è±¡
        current_user: å½“å‰ç”¨æˆ·ï¼ˆä» JWT token è·å–ï¼‰
    """
    try:
        body = await request.json()
        doc_id = body.get("doc_id")
        
        if not doc_id:
            raise HTTPException(status_code=400, detail="doc_id ä¸èƒ½ä¸ºç©º")
    except Exception as e:
        raise HTTPException(status_code=400, detail="è¯·æ±‚ä½“æ ¼å¼é”™è¯¯")
    
    # æŸ¥æ‰¾æ–‡æ¡£æ–‡ä»¶
    file_path = None
    for ext in ['.pdf', '.txt', '.docx', '.pptx']:
        path = os.path.join(UPLOAD_DIR, f"{doc_id}{ext}")
        if os.path.exists(path):
            file_path = path
            break

    if not file_path:
        raise HTTPException(status_code=404, detail="æ–‡æ¡£ä¸å­˜åœ¨")

    try:
        start_time = time.time()

        # 1. è§£ææ–‡æ¡£
        text = kg_service.parse_document(file_path)

        # 2. æ–‡æœ¬åˆ†å—
        chunks = kg_service.split_text(text)

        # 3. å¹¶å‘æŠ½å–å®ä½“å…³ç³»
        triplets = await kg_service.extract_batch_async(chunks)

        # 4. ä¿å­˜åˆ°Neo4j
        kg_service.save_triplets_to_neo4j(triplets, doc_id)

        # 5. ä¿å­˜åˆ°ChromaDB
        kg_service.save_chunks_to_chromadb(chunks, doc_id)

        elapsed_time = time.time() - start_time

        return {
            "doc_id": doc_id,
            "total_chunks": len(chunks),
            "total_triplets": len(triplets),
            "elapsed_time": round(elapsed_time, 2),
            "message": "çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ==================== å›¾è°±æŸ¥è¯¢ ====================

@router.post("/get-graph")
async def get_graph(
    request: GraphQueryRequest,
    current_user: str = Depends(get_current_user)
):
    """
    è·å–å›¾è°±æ•°æ®ï¼ˆç”¨äºå‰ç«¯å¯è§†åŒ–ï¼‰
    
    Args:
        request: å›¾è°±æŸ¥è¯¢è¯·æ±‚
        current_user: å½“å‰ç”¨æˆ·ï¼ˆä» JWT token è·å–ï¼‰
    """
    try:
        graph_data = kg_service.get_graph_data(
            doc_id=request.doc_id,
            limit=request.limit
        )

        return {
            "graph": graph_data,
            "message": "å›¾è°±æ•°æ®è·å–æˆåŠŸ"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ==================== RAGé—®ç­” ====================

@router.get("/available-models")
async def get_available_models():
    """
    è·å–å¯ç”¨çš„AIé—®ç­”æ¨¡å‹åˆ—è¡¨
    """
    from config import QA_MODELS, DEFAULT_QA_MODEL

    models = []
    for model_config in QA_MODELS:
        models.append({
            "name": model_config["name"],
            "model": model_config["model"],
            "description": model_config.get("description", "")  # æ·»åŠ æè¿°å­—æ®µ
        })

    return {
        "models": models,
        "default": DEFAULT_QA_MODEL,
        "message": "è·å–æ¨¡å‹åˆ—è¡¨æˆåŠŸ"
    }


@router.post("/ask")
async def ask_question(request: QuestionRequest):
    """
    RAGé—®ç­”ï¼ˆéæµå¼ï¼‰
    """
    if not request.question:
        raise HTTPException(status_code=400, detail="é—®é¢˜ä¸èƒ½ä¸ºç©º")

    try:
        result = await kg_service.answer_question(
            question=request.question,
            stream=False,
            model_name=request.model_name
        )

        return {
            "answer": result["answer"],
            "sources": result["sources"],
            "message": "é—®ç­”å®Œæˆ"
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/ask-stream")
async def ask_question_stream(request: QuestionRequest):
    """
    RAGé—®ç­”ï¼ˆæµå¼ï¼‰
    """
    if not request.question:
        raise HTTPException(status_code=400, detail="é—®é¢˜ä¸èƒ½ä¸ºç©º")

    try:
        result = await kg_service.answer_question(
            question=request.question,
            stream=True,
            model_name=request.model_name
        )

        # æµå¼ç”Ÿæˆ
        async def generate():
            # é¦–å…ˆè¿”å›æº¯æºä¿¡æ¯
            import json
            sources_data = json.dumps({
                "type": "sources",
                "data": result["sources"]
            }) + "\n"
            yield sources_data

            # ç„¶åæµå¼è¿”å›ç­”æ¡ˆ
            for chunk in result["stream"]:
                if chunk.choices[0].delta.content:
                    answer_data = json.dumps({
                        "type": "answer",
                        "content": chunk.choices[0].delta.content
                    }) + "\n"
                    yield answer_data

        return StreamingResponse(generate(), media_type="text/event-stream")

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/ask-parallel-stream")
async def ask_question_parallel_stream(request: QuestionRequest):
    """
    RAGé—®ç­”ï¼ˆå¹¶è¡Œæµå¼ï¼‰
    ä¸‰ä¸ªéƒ¨åˆ†å¹¶è¡Œå¤„ç†å¹¶æµå¼è¿”å›ï¼š
    1. å‘é‡æ£€ç´¢ç»“æœ (type: vector_chunks)
    2. å›¾æ£€ç´¢ç»“æœ (type: graph_data)
    3. AIç­”æ¡ˆ (type: answer, æµå¼)
    """
    if not request.question:
        raise HTTPException(status_code=400, detail="é—®é¢˜ä¸èƒ½ä¸ºç©º")

    try:
        # ä½¿ç”¨æ–°çš„å¹¶è¡Œæµå¼æ–¹æ³•ï¼Œä¼ é€’å¯¹è¯IDå’Œæ¨¡å‹åç§°
        async def generate():
            async for chunk in kg_service.answer_question_parallel_stream(
                request.question,
                conversation_id=request.conversation_id,
                model_name=request.model_name
            ):
                yield chunk

        return StreamingResponse(
            generate(),
            media_type="text/event-stream",
            headers={
                "Cache-Control": "no-cache",
                "X-Accel-Buffering": "no"
            }
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


# ==================== ç®¡ç†æ¥å£ ====================

@router.delete("/delete-document/{doc_id}")
async def delete_document(doc_id: str):
    """
    åˆ é™¤æ–‡æ¡£åŠå…¶ç›¸å…³æ•°æ®
    """
    file_path = os.path.join(UPLOAD_DIR, f"{doc_id}.pdf")

    # åˆ é™¤æ–‡ä»¶
    if os.path.exists(file_path):
        os.remove(file_path)

    # TODO: ä»Neo4jå’ŒChromaDBä¸­åˆ é™¤ç›¸å…³æ•°æ®
    # è¿™é‡Œéœ€è¦å®ç°æ¸…ç†é€»è¾‘

    return {
        "message": "æ–‡æ¡£åˆ é™¤æˆåŠŸ"
    }


@router.get("/list-documents")
async def list_documents():
    """
    åˆ—å‡ºæ‰€æœ‰å·²ä¸Šä¼ çš„æ–‡æ¡£
    """
    if not os.path.exists(UPLOAD_DIR):
        return {"documents": []}

    files = os.listdir(UPLOAD_DIR)
    documents = []

    for filename in files:
        ext = os.path.splitext(filename)[1].lower()
        if ext in ['.pdf', '.txt', '.docx', '.pptx']:
            doc_id = filename.replace(ext, '')
            file_path = os.path.join(UPLOAD_DIR, filename)
            stat = os.stat(file_path)

            documents.append({
                "doc_id": doc_id,
                "filename": filename,
                "size": stat.st_size,
                "created_at": stat.st_ctime
            })

    return {"documents": documents}


# ==================== ====================

# Kafka é…ç½®
KAFKA_CONFIG = {
    'bootstrap.servers': 'localhost:9092',
    'client.id': 'kg-api-producer'
}

# å…¨å±€ Kafka Producer (å»¶è¿Ÿåˆå§‹åŒ–)
_kafka_producer = None

def get_kafka_producer():
    """è·å– Kafka Producer å®ä¾‹"""
    global _kafka_producer
    if _kafka_producer is None:
        _kafka_producer = KafkaProducer(KAFKA_CONFIG)
    return _kafka_producer


# ==================== å¼‚æ­¥æ–‡æ¡£å¤„ç†ï¼ˆKafka + SSEï¼‰====================

@router.post("/upload-async")
async def upload_document_async(
    file: UploadFile = File(...),
    current_user: str = Depends(get_current_user)
):
    """
    å¼‚æ­¥ä¸Šä¼ æ–‡æ¡£ï¼ˆä½¿ç”¨ Kafka å¤„ç† + SSE æ¨é€è¿›åº¦ï¼‰
    
    æµç¨‹ï¼š
    1. ä¿å­˜æ–‡ä»¶åˆ°æœ¬åœ°
    2. å‘é€ä»»åŠ¡åˆ° Kafka
    3. ç«‹å³è¿”å› task_id
    4. å‰ç«¯é€šè¿‡ SSE ç›‘å¬å¤„ç†è¿›åº¦
    
    è¿”å›ï¼š
    - task_id: ä»»åŠ¡IDï¼Œç”¨äº SSE ç›‘å¬
    - sse_url: SSE è¿æ¥åœ°å€
    """
    # éªŒè¯æ–‡ä»¶ç±»å‹
    allowed_extensions = {'.pdf', '.txt', '.docx', '.pptx'}
    file_ext = os.path.splitext(file.filename)[1].lower()
    if file_ext not in allowed_extensions:
        raise HTTPException(status_code=400, detail="åªæ”¯æŒ PDFã€TXTã€DOCXã€PPTX æ–‡ä»¶")

    # è¯»å–æ–‡ä»¶å†…å®¹
    try:
        content = await file.read()
        file_hash = hashlib.md5(content).hexdigest()
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}")

    # ä½¿ç”¨å¸ƒéš†è¿‡æ»¤å™¨æ£€æŸ¥é‡å¤
    doc_exists, _ = is_document_uploaded_with_warmup(file_hash, fallback_to_db=True)
    
    if doc_exists:
        return {
            "error": "æ–‡æ¡£å·²å­˜åœ¨",
            "duplicate": True,
            "file_hash": file_hash,
            "message": "è¯¥æ–‡æ¡£å·²ä¸Šä¼ è¿‡ï¼Œè¯·å‹¿é‡å¤ä¸Šä¼ "
        }

    # ç”Ÿæˆä»»åŠ¡ ID
    task_id = str(uuid.uuid4())
    doc_id = str(uuid.uuid4())

    # ä¿å­˜æ–‡ä»¶
    file_path = os.path.join(UPLOAD_DIR, f"{doc_id}{file_ext}")
    try:
        with open(file_path, "wb") as f:
            f.write(content)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)}")

    # æ ‡è®°æ–‡æ¡£å·²ä¸Šä¼ 
    mark_document_uploaded(file_hash, force_save=True)

    # åˆ›å»ºä»»åŠ¡è®°å½•
    task_info = task_manager.create_task(task_id, current_user, "kb_build")

    # å‘é€åˆ° Kafka
    producer = get_kafka_producer()
    kafka_message = {
        "task_id": task_id,
        "doc_id": doc_id,
        "user_id": current_user,
        "filename": file.filename,
        "file_path": file_path,
        "file_size": len(content),
        "file_hash": file_hash,
        "created_at": time.time()
    }

    try:
        producer.produce(
            'doc-upload',
            key=task_id.encode('utf-8'),
            value=json.dumps(kafka_message).encode('utf-8'),
            callback=lambda msg, err: None  # å¯ä»¥æ·»åŠ å›è°ƒå¤„ç†å‘é€ç»“æœ
        )
        producer.flush()  # ç­‰å¾…æ¶ˆæ¯å‘é€å®Œæˆ
    except Exception as e:
        # Kafka å‘é€å¤±è´¥ï¼Œåˆ é™¤æ–‡ä»¶å¹¶æŠ¥é”™
        if os.path.exists(file_path):
            os.remove(file_path)
        task_manager.fail_task(task_id, f"Kafka å‘é€å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Kafka å‘é€å¤±è´¥: {str(e)}")

    # å¼‚æ­¥ä¿å­˜æ–‡æ¡£å…ƒæ•°æ®ï¼ˆæ·»åŠ é”™è¯¯å¤„ç†ï¼‰
    async def safe_save_metadata():
        try:
            await save_document_metadata_async(
                doc_id=doc_id,
                file_hash=file_hash,
                filename=file.filename,
                file_extension=file_ext,
                file_size=len(content),
                file_path=file_path,
                text_length=0  # åˆå§‹ä¸º 0ï¼Œå¤„ç†åä¼šæ›´æ–°
            )
        except Exception as e:
            # è¿™é‡Œå¯ä»¥è®°å½•åˆ°æ—¥å¿—ç³»ç»Ÿï¼Œä½†ä¸åº”æŠ›å‡ºå¼‚å¸¸å½±å“ä¸»æµç¨‹
            import logging
            logger = logging.getLogger(__name__)
            logger.error(f"å¼‚æ­¥ä¿å­˜æ–‡æ¡£å…ƒæ•°æ®å¤±è´¥: {str(e)}")
    
    asyncio.create_task(safe_save_metadata())

    return {
        "task_id": task_id,
        "doc_id": doc_id,
        "filename": file.filename,
        "status": "processing",
        "message": "æ–‡æ¡£å·²ä¸Šä¼ ï¼Œæ­£åœ¨åå°å¤„ç†ä¸­...",
        "sse_url": f"/api/kg/task/stream/{task_id}",
        "poll_url": f"/api/kg/task/{task_id}"
    }


@router.get("/task/stream/{task_id}")
async def stream_task_progress(
    task_id: str,
    current_user: str = Depends(get_current_user_from_query)  # ä» URL query å‚æ•°è·å– token
):
    """
    SSE æµå¼æ¥å£ï¼šå®æ—¶æ¨é€ä»»åŠ¡å¤„ç†è¿›åº¦
    
    Args:
        task_id: ä»»åŠ¡ID
    
    Returns:
        StreamingResponse: SSE æµ
    """
    async def event_generator():
        """SSE äº‹ä»¶ç”Ÿæˆå™¨"""
        last_progress = -1
        
        while True:
            try:
                # ä» Redis è·å–ä»»åŠ¡çŠ¶æ€
                task_info = task_manager.get_task_status(task_id)
                
                if task_info is None:
                    # ä»»åŠ¡ä¸å­˜åœ¨ï¼Œå¯èƒ½å·²è¿‡æœŸ
                    yield f"data: {json.dumps({'type': 'error', 'message': 'ä»»åŠ¡ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ'})}\n\n"
                    break
                
                status = task_info.get("status")
                progress = task_info.get("progress", 0)
                stage = task_info.get("stage", "")
                message = task_info.get("message", "")
                
                # åªæœ‰è¿›åº¦å˜åŒ–æˆ–çŠ¶æ€å˜åŒ–æ—¶æ‰æ¨é€
                if progress != last_progress or status in ["completed", "failed"]:
                    
                    if status == "processing":
                        payload = {
                            "type": "progress",
                            "progress": progress,
                            "stage": stage,
                            "message": message or "å¤„ç†ä¸­..."
                        }
                        yield f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"
                    
                    elif status == "completed":
                        # ä»»åŠ¡å®Œæˆï¼Œæ¨é€å®Œæ•´ç»“æœ
                        result = task_info.get("result", {})
                        payload = {
                            "type": "completed",
                            "progress": 100,
                            "stage": "completed",
                            "data": result
                        }
                        yield f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"
                        break
                    
                    elif status == "failed":
                        # ä»»åŠ¡å¤±è´¥ï¼Œæ¨é€é”™è¯¯ä¿¡æ¯
                        error_msg = task_info.get("error_message", "æœªçŸ¥é”™è¯¯")
                        payload = {
                            "type": "error",
                            "message": error_msg
                        }
                        yield f"data: {json.dumps(payload, ensure_ascii=False)}\n\n"
                        break
                    
                    last_progress = progress
                
                # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦è¶…æ—¶ï¼ˆ2 å°æ—¶ï¼‰
                elapsed = time.time() - task_info.get("created_at", time.time())
                if elapsed > 7200:
                    yield f"data: {json.dumps({'type': 'error', 'message': 'ä»»åŠ¡è¶…æ—¶'})}\n\n"
                    break
                
                # ç­‰å¾… 1 ç§’åå†æ¬¡æ£€æŸ¥
                await asyncio.sleep(1)
                
            except Exception as e:
                yield f"data: {json.dumps({'type': 'error', 'message': f'SSE é”™è¯¯: {str(e)}'})}\n\n"
                break
    
    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


@router.get("/task/{task_id}")
async def get_task_status_endpoint(task_id: str):
    """
    è½®è¯¢æ¥å£ï¼šè·å–ä»»åŠ¡çŠ¶æ€ï¼ˆç”¨äº SSE ä¸å¯ç”¨æ—¶çš„é™çº§æ–¹æ¡ˆï¼‰
    
    Args:
        task_id: ä»»åŠ¡ID
    
    Returns:
        ä»»åŠ¡çŠ¶æ€ä¿¡æ¯
    """
    task_info = task_manager.get_task_status(task_id)
    
    if task_info is None:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ")
    
    # è¿”å›å»æ•æ„Ÿä¿¡æ¯çš„ä»»åŠ¡æ•°æ®
    return {
        "task_id": task_info.get("task_id"),
        "status": task_info.get("status"),
        "progress": task_info.get("progress", 0),
        "stage": task_info.get("stage", ""),
        "message": task_info.get("message", ""),
        "created_at": task_info.get("created_at"),
        "updated_at": task_info.get("updated_at"),
        "result": task_info.get("result") if task_info.get("status") == "completed" else None,
        "error_message": task_info.get("error_message") if task_info.get("status") == "failed" else None
    }
